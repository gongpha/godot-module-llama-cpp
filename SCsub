#!/usr/bin/env python

from SCons.Script import Environment
import os
from SCons.Script import Exit
import subprocess

Import('env')
Import("env_modules")

env_llama = env_modules.Clone()

# retrieve macro info
try:
	build_number = int(subprocess.check_output(
		["git", "rev-list", "--count", "HEAD"],
		cwd="thirdparty/llama",
		universal_newlines=True
	).strip())
except Exception:
	build_number = 0

try:
	commit = subprocess.check_output(
			["git", "rev-parse", "--short=7", "HEAD"],
			cwd="thirdparty/llama",
			universal_newlines=True
	).strip()
except Exception:
	commit = "unknown"

print("llama.cpp build number: " + str(build_number) + ", commit: " + commit)

env_llama.Append(CPPDEFINES=[
	'LLAMA_CPP_BUILD_NUMBER=' + str(build_number),
	'LLAMA_CPP_VERSION="\\\"' + "b" + str(build_number) + '\\\""',
	'LLAMA_CPP_COMMIT="\\\"' + commit + '\\\""',
	'GGML_VERSION="\\\"' + "b" + str(build_number) + '\\\""',
	'GGML_COMMIT="\\\"' + commit + '\\\""',
])

# Thirdparty source files

thirdparty_obj = []

env_llama.Append(CPPDEFINES=[
	'LLAMA_CPP_COMPILER="\\\"' + ("msvc" if env.msvc else "gcc/clang") + '\\\""',
	'LLAMA_CPP_BUILD_TARGET="\\\"' + env["platform"] + '\\\""',
])

# yes. you all know godot had disabled exception handling entirely.
# BUT llama.cpp and its vendors use it extensively.
# we can manually disable it by hand. but i would rather kill myself,
# so i have to enable it here... even though it was dangerous.
# (im very thankful nlomann json allows me to disable exceptions
# but my dawg llama.cpp uses them for catching unnecessary json parser error
# like they're throwing dynamites in a lake for fishes)
env_llama.Append(CXXFLAGS=["/EHsc"])


if env["builtin_llama"]:
	# Thirdparty source files
	thirdparty_dir = "thirdparty/llama/"

	env_llama.Append(CPPPATH=[
		thirdparty_dir,
		thirdparty_dir + "/include",

		thirdparty_dir + "/ggml/include",
		thirdparty_dir + "/ggml/src",
		thirdparty_dir + "/ggml/src/ggml-cpu",
		thirdparty_dir + "/vendor",
	])

	thirdparty_sources = [
		"ggml/src/ggml.cpp",
		"ggml/src/ggml-alloc.c",
		"ggml/src/ggml-backend.cpp",
		"ggml/src/ggml-backend-reg.cpp",
		"ggml/src/ggml-opt.cpp",
		"ggml/src/ggml-threading.cpp",
		"ggml/src/ggml-quants.c",
		"ggml/src/gguf.cpp",


		"ggml/src/ggml-cpu/ggml-cpu.cpp",
		"ggml/src/ggml-cpu/repack.cpp",
		"ggml/src/ggml-cpu/hbm.cpp",
		"ggml/src/ggml-cpu/binary-ops.cpp",
		"ggml/src/ggml-cpu/unary-ops.cpp",
		"ggml/src/ggml-cpu/vec.cpp",
		"ggml/src/ggml-cpu/ops.cpp",
		"ggml/src/ggml-cpu/quants.c",
		"ggml/src/ggml-cpu/traits.cpp",

		"src/llama.cpp",
		"src/llama-adapter.cpp",
		"src/llama-arch.cpp",
		"src/llama-batch.cpp",
		"src/llama-chat.cpp",
		"src/llama-context.cpp",
		"src/llama-cparams.cpp",
		"src/llama-grammar.cpp",
		"src/llama-graph.cpp",
		"src/llama-hparams.cpp",
		"src/llama-impl.cpp",
		"src/llama-io.cpp",
		"src/llama-kv-cache.cpp",
		"src/llama-kv-cache-iswa.cpp",
		"src/llama-memory.cpp",
		"src/llama-memory-hybrid.cpp",
		"src/llama-memory-recurrent.cpp",
		"src/llama-mmap.cpp",
		"src/llama-model-loader.cpp",
		"src/llama-model-saver.cpp",
		"src/llama-model.cpp",
		"src/llama-quant.cpp",
		"src/llama-sampling.cpp",
		"src/llama-vocab.cpp",
		"src/unicode-data.cpp",
		"src/unicode.cpp",
	]

	env_thirdparty = env_llama.Clone()
	env_thirdparty.disable_warnings()

	if env["vulkan"]:
		if env.get("use_volk", False):
			print("using volk and llama.cpp with vulkan support is not supported at the time")
			Exit(1)

		env_thirdparty.Append(CPPDEFINES=[
			'GGML_USE_VULKAN'
		])
		#env_llama.Append(CPPPATH=['#thirdparty/vulkan/include'])

		if False : # incomplete
			vulkan_shaders_dir = thirdparty_dir + "ggml/src/ggml-vulkan/vulkan-shaders"
			gen_src = vulkan_shaders_dir + "/vulkan-shaders-gen.cpp"

			tool_env = Environment(tools=['default'], ENV=os.environ.copy())

			shader_tool = tool_env.Program(target="#bin/vulkan-shaders-gen", source=gen_src)

			shader_targets = [
				vulkan_shaders_dir + "/../ggml-vulkan-shaders.hpp",
				vulkan_shaders_dir + "/../ggml-vulkan-shaders.cpp",
			]
			tool_env.Command(
				shader_targets,
				shader_tool,
				'"$SOURCE"',
				chdir=tool_env.Dir(vulkan_shaders_dir).abspath,
			)

		thirdparty_sources += [
			"ggml/src/ggml-vulkan/ggml-vulkan-shaders.cpp",
			"ggml/src/ggml-vulkan/ggml-vulkan.cpp",
		]

	thirdparty_sources = [thirdparty_dir + file for file in thirdparty_sources]

	env_thirdparty.Append(CPPDEFINES=['GGML_USE_CPU'])
	
	env_thirdparty.add_source_files(thirdparty_obj, thirdparty_sources)

	env_thirdparty.add_source_files(thirdparty_obj, 'arch/*.cpp')
	env_thirdparty.add_source_files(thirdparty_obj, 'arch/*.c')
	env_thirdparty.add_source_files(thirdparty_obj, 'ggml_core_c.c')
	env_thirdparty.add_source_files(thirdparty_obj, 'ggml_cpu_core_c.c')
	env_thirdparty.add_source_files(thirdparty_obj, 'build_info_stubs.cpp')

	common_helpers = [
		thirdparty_dir + 'common/arg.cpp',
		thirdparty_dir + 'common/chat-parser.cpp',
		thirdparty_dir + 'common/chat.cpp',
		thirdparty_dir + 'common/common.cpp',
		thirdparty_dir + 'common/console.cpp',
		thirdparty_dir + 'common/json-partial.cpp',
		thirdparty_dir + 'common/json-schema-to-grammar.cpp',
		thirdparty_dir + 'common/llguidance.cpp',
		thirdparty_dir + 'common/log.cpp',
		thirdparty_dir + 'common/ngram-cache.cpp',
		thirdparty_dir + 'common/regex-partial.cpp',
		thirdparty_dir + 'common/sampling.cpp',
		thirdparty_dir + 'common/speculative.cpp',
	]
	env_thirdparty.add_source_files(thirdparty_obj, common_helpers)
	env.modules_sources += thirdparty_obj

# Godot source files

module_obj = []

env_llama.add_source_files(module_obj, 'llama_context.cpp')
env_llama.add_source_files(module_obj, 'llama_vocab.cpp')
env_llama.add_source_files(module_obj, 'llama_sampler_chain.cpp')
env_llama.add_source_files(module_obj, 'llama_sampler.cpp')
env_llama.add_source_files(module_obj, 'sampler/*.cpp')
env_llama.add_source_files(module_obj, 'llama_cpp.cpp')
env_llama.add_source_files(module_obj, 'llama_gguf.cpp')
env_llama.add_source_files(module_obj, 'llama_tool.cpp')
env_llama.add_source_files(module_obj, 'llama_tool_callable.cpp')
env_llama.add_source_files(module_obj, 'llama_model_instance.cpp')
env_llama.add_source_files(module_obj, 'common/*.cpp')
env_llama.add_source_files(module_obj, 'register_types.cpp')

env.modules_sources += module_obj

env.Depends(module_obj, thirdparty_obj)